{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nprand\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math as math\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original data = df\n",
    "df = pd.read_csv('data.csv',\n",
    "    header=None,\n",
    "    index_col=False).T"
   ]
  },
  {
   "source": [
    "Select labels, light and feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesions=df.iloc[:,1].apply(pd.to_numeric)\n",
    "light=df.iloc[:,2].apply(pd.to_numeric)\n",
    "features=df.iloc[:,3:-1].apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = lesions.values.reshape(len(lesions), 1)\n",
    "lesions_encoded = onehot_encoder.fit_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, lesions_encoded, test_size=0.2,stratify=lesions_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "class calculateInteraction(layers.Layer):\n",
    "    def __init__(self,featureSize):\n",
    "        super(calculateInteraction, self).__init__()\n",
    "        mask = tf.zeros_initializer()\n",
    "        self.mask = tf.Variable(\n",
    "            initial_value=mask(shape=(1, featureSize), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "    \n",
    "    def call(self, x):\n",
    "        Mx=tf.math.multiply(self.mask,x)\n",
    "        Rxx=tf.matmul(Mx,Mx,transpose_b=True)\n",
    "\n",
    "        query_value_attention_seq = layers.Attention()([Rxx, Rxx])\n",
    "        query_value_attention_seq=tf.expand_dims(query_value_attention_seq,2)\n",
    "        query_value_attention = layers.GlobalAveragePooling1D()(\n",
    "            query_value_attention_seq)\n",
    "\n",
    "        concatenated = layers.Concatenate()(\n",
    "            [Mx, query_value_attention])\n",
    "        print(concatenated.shape)\n",
    "        return concatenated\n",
    "\n",
    "def getModel(inputSize):\n",
    "    \n",
    "    inputs = layers.Input(shape=inputSize)\n",
    "    concatenated=calculateInteraction(inputs.shape[1])(inputs)\n",
    "    concatenated=layers.Flatten()(concatenated)\n",
    "    x=layers.Dense(32)(concatenated)\n",
    "    x=layers.Dense(16)(x)\n",
    "    output=layers.Dense(3,activation='softmax')(x)\n",
    "\n",
    "    METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "     ]   \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='nadam',loss='categorical_crossentropy',metrics=METRICS)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 0.5854 - accuracy: 0.8768 - precision: 0.8282 - recall: 0.7979 - auc: 0.9400 - val_loss: 0.6873 - val_accuracy: 0.8667 - val_precision: 0.8261 - val_recall: 0.7600 - val_auc: 0.8884\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.8369 - precision: 0.7661 - recall: 0.7345 - auc: 0.9359 - val_loss: 1.0525 - val_accuracy: 0.6800 - val_precision: 0.5217 - val_recall: 0.4800 - val_auc: 0.7808\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.8371 - precision: 0.7721 - recall: 0.7228 - auc: 0.8973 - val_loss: 0.7814 - val_accuracy: 0.8400 - val_precision: 0.8095 - val_recall: 0.6800 - val_auc: 0.8632\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.8940 - precision: 0.8473 - recall: 0.8316 - auc: 0.9422 - val_loss: 0.7726 - val_accuracy: 0.8267 - val_precision: 0.7500 - val_recall: 0.7200 - val_auc: 0.8636\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.8611 - precision: 0.7950 - recall: 0.7860 - auc: 0.9298 - val_loss: 0.8302 - val_accuracy: 0.8133 - val_precision: 0.7391 - val_recall: 0.6800 - val_auc: 0.8492\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.8918 - precision: 0.8629 - recall: 0.8022 - auc: 0.9425 - val_loss: 0.6855 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8852\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.9006 - precision: 0.8635 - recall: 0.8339 - auc: 0.9580 - val_loss: 0.8371 - val_accuracy: 0.8000 - val_precision: 0.7273 - val_recall: 0.6400 - val_auc: 0.8504\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.8889 - precision: 0.8568 - recall: 0.8016 - auc: 0.9384 - val_loss: 0.7188 - val_accuracy: 0.8667 - val_precision: 0.8261 - val_recall: 0.7600 - val_auc: 0.8876\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.8919 - precision: 0.8499 - recall: 0.8209 - auc: 0.9620 - val_loss: 0.7069 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8864\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.9043 - precision: 0.8675 - recall: 0.8404 - auc: 0.9452 - val_loss: 0.9447 - val_accuracy: 0.7467 - val_precision: 0.6364 - val_recall: 0.5600 - val_auc: 0.8128\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.8877 - precision: 0.8453 - recall: 0.8138 - auc: 0.9282 - val_loss: 0.6877 - val_accuracy: 0.8533 - val_precision: 0.7917 - val_recall: 0.7600 - val_auc: 0.8836\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.8979 - precision: 0.8521 - recall: 0.8386 - auc: 0.9527 - val_loss: 0.6648 - val_accuracy: 0.8400 - val_precision: 0.7600 - val_recall: 0.7600 - val_auc: 0.8864\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.8953 - precision: 0.8497 - recall: 0.8328 - auc: 0.9527 - val_loss: 0.6709 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8888\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.8385 - precision: 0.7797 - recall: 0.7188 - auc: 0.9277 - val_loss: 0.8898 - val_accuracy: 0.7733 - val_precision: 0.6667 - val_recall: 0.6400 - val_auc: 0.8336\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.8663 - precision: 0.8038 - recall: 0.7924 - auc: 0.9557 - val_loss: 0.7576 - val_accuracy: 0.8667 - val_precision: 0.8261 - val_recall: 0.7600 - val_auc: 0.8716\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.8880 - precision: 0.8407 - recall: 0.8190 - auc: 0.9398 - val_loss: 0.7701 - val_accuracy: 0.8267 - val_precision: 0.7500 - val_recall: 0.7200 - val_auc: 0.8688\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.8448 - precision: 0.7854 - recall: 0.7365 - auc: 0.9363 - val_loss: 0.8062 - val_accuracy: 0.7867 - val_precision: 0.6957 - val_recall: 0.6400 - val_auc: 0.8544\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.8862 - precision: 0.8399 - recall: 0.8137 - auc: 0.9474 - val_loss: 0.7173 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8776\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.9040 - precision: 0.8731 - recall: 0.8346 - auc: 0.9645 - val_loss: 0.7502 - val_accuracy: 0.8533 - val_precision: 0.7917 - val_recall: 0.7600 - val_auc: 0.8764\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.8824 - precision: 0.8379 - recall: 0.8026 - auc: 0.9388 - val_loss: 0.7017 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8800\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.8674 - precision: 0.8068 - recall: 0.7913 - auc: 0.9367 - val_loss: 0.8206 - val_accuracy: 0.8133 - val_precision: 0.7391 - val_recall: 0.6800 - val_auc: 0.8560\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.8686 - precision: 0.8097 - recall: 0.7927 - auc: 0.9372 - val_loss: 0.7697 - val_accuracy: 0.8400 - val_precision: 0.7826 - val_recall: 0.7200 - val_auc: 0.8708\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.8952 - precision: 0.8464 - recall: 0.8375 - auc: 0.9545 - val_loss: 0.6999 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8900\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.9020 - precision: 0.8689 - recall: 0.8310 - auc: 0.9658 - val_loss: 0.6110 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.8932\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.8637 - precision: 0.8133 - recall: 0.7657 - auc: 0.9214 - val_loss: 0.7701 - val_accuracy: 0.8400 - val_precision: 0.7826 - val_recall: 0.7200 - val_auc: 0.8696\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.8798 - precision: 0.8369 - recall: 0.7956 - auc: 0.9335 - val_loss: 0.7467 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8760\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.8813 - precision: 0.8490 - recall: 0.7857 - auc: 0.9489 - val_loss: 0.7622 - val_accuracy: 0.8667 - val_precision: 0.8261 - val_recall: 0.7600 - val_auc: 0.8760\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.8798 - precision: 0.8524 - recall: 0.7737 - auc: 0.9389 - val_loss: 0.6878 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8888\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.9401 - precision: 0.9175 - recall: 0.9007 - auc: 0.9797 - val_loss: 0.9050 - val_accuracy: 0.7867 - val_precision: 0.6957 - val_recall: 0.6400 - val_auc: 0.8352\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.8869 - precision: 0.8349 - recall: 0.8230 - auc: 0.9449 - val_loss: 0.6524 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8920\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.9033 - precision: 0.8626 - recall: 0.8442 - auc: 0.9469 - val_loss: 0.6931 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8856\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.9189 - precision: 0.8852 - recall: 0.8689 - auc: 0.9566 - val_loss: 0.7055 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8852\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.8847 - precision: 0.8472 - recall: 0.7983 - auc: 0.9439 - val_loss: 0.6940 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8888\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.9369 - precision: 0.9094 - recall: 0.9000 - auc: 0.9738 - val_loss: 0.7370 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8816\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.8503 - precision: 0.7959 - recall: 0.7416 - auc: 0.9400 - val_loss: 0.8249 - val_accuracy: 0.8133 - val_precision: 0.7391 - val_recall: 0.6800 - val_auc: 0.8568\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.9026 - precision: 0.8721 - recall: 0.8295 - auc: 0.9674 - val_loss: 0.9338 - val_accuracy: 0.7867 - val_precision: 0.6957 - val_recall: 0.6400 - val_auc: 0.8232\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.9151 - precision: 0.8764 - recall: 0.8674 - auc: 0.9590 - val_loss: 0.7533 - val_accuracy: 0.8667 - val_precision: 0.8261 - val_recall: 0.7600 - val_auc: 0.8784\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.8649 - precision: 0.8018 - recall: 0.7893 - auc: 0.9523 - val_loss: 0.8271 - val_accuracy: 0.8400 - val_precision: 0.7826 - val_recall: 0.7200 - val_auc: 0.8612\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.8711 - precision: 0.8072 - recall: 0.8059 - auc: 0.9408 - val_loss: 0.8277 - val_accuracy: 0.8133 - val_precision: 0.7391 - val_recall: 0.6800 - val_auc: 0.8632\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.8708 - precision: 0.8087 - recall: 0.8018 - auc: 0.9365 - val_loss: 0.6722 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8956\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.8591 - precision: 0.8034 - recall: 0.7632 - auc: 0.9356 - val_loss: 0.7123 - val_accuracy: 0.8533 - val_precision: 0.7917 - val_recall: 0.7600 - val_auc: 0.8840\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.8910 - precision: 0.8465 - recall: 0.8215 - auc: 0.9502 - val_loss: 0.6263 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8968\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.8892 - precision: 0.8356 - recall: 0.8309 - auc: 0.9533 - val_loss: 0.6132 - val_accuracy: 0.8400 - val_precision: 0.7600 - val_recall: 0.7600 - val_auc: 0.8928\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.8821 - precision: 0.8231 - recall: 0.8231 - auc: 0.9313 - val_loss: 0.6839 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8872\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.8730 - precision: 0.8183 - recall: 0.7962 - auc: 0.9501 - val_loss: 0.7200 - val_accuracy: 0.8533 - val_precision: 0.7917 - val_recall: 0.7600 - val_auc: 0.8760\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.9008 - precision: 0.8542 - recall: 0.8468 - auc: 0.9649 - val_loss: 0.9999 - val_accuracy: 0.7200 - val_precision: 0.5833 - val_recall: 0.5600 - val_auc: 0.8016\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.8607 - precision: 0.7967 - recall: 0.7824 - auc: 0.9247 - val_loss: 0.8106 - val_accuracy: 0.8400 - val_precision: 0.7826 - val_recall: 0.7200 - val_auc: 0.8668\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.9002 - precision: 0.8569 - recall: 0.8413 - auc: 0.9503 - val_loss: 0.7030 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8824\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.9311 - precision: 0.9156 - recall: 0.8737 - auc: 0.9761 - val_loss: 0.6460 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8940\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.9012 - precision: 0.8693 - recall: 0.8282 - auc: 0.9541 - val_loss: 0.7394 - val_accuracy: 0.8667 - val_precision: 0.8261 - val_recall: 0.7600 - val_auc: 0.8800\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8915 - precision: 0.8446 - recall: 0.8260 - auc: 0.9666 - val_loss: 0.8319 - val_accuracy: 0.8267 - val_precision: 0.7727 - val_recall: 0.6800 - val_auc: 0.8624\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.8623 - precision: 0.8000 - recall: 0.7830 - auc: 0.9230 - val_loss: 0.7492 - val_accuracy: 0.8667 - val_precision: 0.8261 - val_recall: 0.7600 - val_auc: 0.8776\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.8940 - precision: 0.8439 - recall: 0.8366 - auc: 0.9581 - val_loss: 0.7505 - val_accuracy: 0.8667 - val_precision: 0.8261 - val_recall: 0.7600 - val_auc: 0.8776\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.8745 - precision: 0.8225 - recall: 0.7955 - auc: 0.9427 - val_loss: 0.8518 - val_accuracy: 0.8000 - val_precision: 0.7083 - val_recall: 0.6800 - val_auc: 0.8556\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.8777 - precision: 0.8279 - recall: 0.7977 - auc: 0.9511 - val_loss: 0.7463 - val_accuracy: 0.8400 - val_precision: 0.7826 - val_recall: 0.7200 - val_auc: 0.8764\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.9210 - precision: 0.8836 - recall: 0.8787 - auc: 0.9708 - val_loss: 0.6829 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8836\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.8916 - precision: 0.8406 - recall: 0.8328 - auc: 0.9590 - val_loss: 0.6844 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8876\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.8868 - precision: 0.8562 - recall: 0.7942 - auc: 0.9567 - val_loss: 0.7495 - val_accuracy: 0.8667 - val_precision: 0.8261 - val_recall: 0.7600 - val_auc: 0.8812\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.8576 - precision: 0.7902 - recall: 0.7800 - auc: 0.9527 - val_loss: 0.6381 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8960\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.8853 - precision: 0.8322 - recall: 0.8215 - auc: 0.9565 - val_loss: 0.9958 - val_accuracy: 0.7333 - val_precision: 0.6087 - val_recall: 0.5600 - val_auc: 0.8172\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.8546 - precision: 0.7957 - recall: 0.7567 - auc: 0.9381 - val_loss: 0.6994 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8832\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.8824 - precision: 0.8290 - recall: 0.8153 - auc: 0.9480 - val_loss: 0.8386 - val_accuracy: 0.8400 - val_precision: 0.7826 - val_recall: 0.7200 - val_auc: 0.8632\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.8747 - precision: 0.8180 - recall: 0.8036 - auc: 0.9352 - val_loss: 0.7260 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8860\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.9202 - precision: 0.8830 - recall: 0.8766 - auc: 0.9639 - val_loss: 0.8393 - val_accuracy: 0.8267 - val_precision: 0.7727 - val_recall: 0.6800 - val_auc: 0.8660\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.8375 - precision: 0.7634 - recall: 0.7454 - auc: 0.9328 - val_loss: 0.7559 - val_accuracy: 0.8667 - val_precision: 0.8261 - val_recall: 0.7600 - val_auc: 0.8728\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.9238 - precision: 0.8857 - recall: 0.8857 - auc: 0.9679 - val_loss: 0.6859 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8900\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.9094 - precision: 0.8913 - recall: 0.8307 - auc: 0.9517 - val_loss: 0.6871 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8860\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.9044 - precision: 0.8643 - recall: 0.8461 - auc: 0.9612 - val_loss: 0.6224 - val_accuracy: 0.8400 - val_precision: 0.7600 - val_recall: 0.7600 - val_auc: 0.8984\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.8574 - precision: 0.7955 - recall: 0.7708 - auc: 0.9362 - val_loss: 0.6542 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8960\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.8981 - precision: 0.8654 - recall: 0.8222 - auc: 0.9446 - val_loss: 0.8271 - val_accuracy: 0.8400 - val_precision: 0.7826 - val_recall: 0.7200 - val_auc: 0.8696\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.8925 - precision: 0.8524 - recall: 0.8198 - auc: 0.9557 - val_loss: 0.7020 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8824\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.8968 - precision: 0.8556 - recall: 0.8299 - auc: 0.9413 - val_loss: 0.6956 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8884\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.9299 - precision: 0.9090 - recall: 0.8787 - auc: 0.9659 - val_loss: 1.0237 - val_accuracy: 0.7200 - val_precision: 0.5833 - val_recall: 0.5600 - val_auc: 0.8096\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.8741 - precision: 0.8197 - recall: 0.7979 - auc: 0.9364 - val_loss: 0.6861 - val_accuracy: 0.8800 - val_precision: 0.8333 - val_recall: 0.8000 - val_auc: 0.8896\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.8413 - precision: 0.7672 - recall: 0.7531 - auc: 0.9210 - val_loss: 0.7270 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.8884\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3296 - accuracy: 0.9564 - precision: 0.9424 - recall: 0.9257 - auc: 0.9832 - val_loss: 0.9105 - val_accuracy: 0.7600 - val_precision: 0.6522 - val_recall: 0.6000 - val_auc: 0.8448\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.8726 - precision: 0.8143 - recall: 0.8005 - auc: 0.9436 - val_loss: 0.6328 - val_accuracy: 0.8400 - val_precision: 0.7600 - val_recall: 0.7600 - val_auc: 0.8980\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.9166 - precision: 0.8769 - recall: 0.8720 - auc: 0.9529 - val_loss: 0.8421 - val_accuracy: 0.8533 - val_precision: 0.7917 - val_recall: 0.7600 - val_auc: 0.8660\n",
      "Epoch 00300: early stopping\n"
     ]
    }
   ],
   "source": [
    "total=lesions_encoded.shape[0]\n",
    "c1=len(np.where(lesions_encoded[:,0]==1)[0])\n",
    "c2=len(np.where(lesions_encoded[:,1]==1)[0])\n",
    "c3=len(np.where(lesions_encoded[:,2]==1)[0])\n",
    "\n",
    "model=getModel(X_train.shape[1])\n",
    "\n",
    "weight_for_0 = (1 / c1)*(total)/3.0 \n",
    "weight_for_1 = (1 / c2)*(total)/3.0\n",
    "weight_for_2 = (1 / c3)*(total)/3.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1,2:weight_for_2}\n",
    "class_weight\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_recall', mode='max', verbose=1,baseline=0.85,patience=300)\n",
    "history=model.fit(X_train,y_train,epochs=1000,batch_size=8,validation_split=0.2,class_weight=class_weight,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(None, 698)\n              precision    recall  f1-score   support\n\n           1       0.70      0.78      0.74         9\n           2       0.38      0.83      0.53         6\n           3       0.88      0.44      0.58        16\n\n    accuracy                           0.61        31\n   macro avg       0.65      0.68      0.62        31\nweighted avg       0.73      0.61      0.62        31\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labelNames=['hyperplasic', 'serrated', 'adenoma']\n",
    "y_output=model.predict(X_test)\n",
    "y_output_transformed= onehot_encoder.inverse_transform(y_output)\n",
    "y_test_transformed= onehot_encoder.inverse_transform(y_test)\n",
    "print(classification_report(y_test_transformed, y_output_transformed, labels=[1,2,3]))\n",
    "\n",
    "y_output_train=model.predict(X_train)\n",
    "y_output_transformed_train= onehot_encoder.inverse_transform(y_output_train)\n",
    "y_train_transformed= onehot_encoder.inverse_transform(y_train)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}