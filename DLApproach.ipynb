{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nprand\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math as math\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original data = df\n",
    "df = pd.read_csv('data.csv',\n",
    "    header=None,\n",
    "    index_col=False).T"
   ]
  },
  {
   "source": [
    "Select labels, light and feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesions=df.iloc[:,1].apply(pd.to_numeric)\n",
    "light=df.iloc[:,2].apply(pd.to_numeric)\n",
    "features=df.iloc[:,3:-1].apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = lesions.values.reshape(len(lesions), 1)\n",
    "lesions_encoded = onehot_encoder.fit_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, lesions_encoded, test_size=0.2,stratify=lesions_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalize_with_moments(x, axes=[0, 1], epsilon=1e-8):\n",
    "    mean, variance = tf.nn.moments(x, axes=axes)\n",
    "    x_normed = (x - mean) / tf.sqrt(variance + epsilon) # epsilon to avoid dividing by zero\n",
    "    return x_normed\n",
    "\n",
    "class calculateInteraction(layers.Layer):\n",
    "    def __init__(self,featureSize):\n",
    "        super(calculateInteraction, self).__init__()\n",
    "        mask = tf.random_normal_initializer()\n",
    "        self.mask = tf.Variable(\n",
    "            initial_value=mask(shape=(1, featureSize), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        randomIn = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=randomIn(shape=(featureSize, 13), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "    \n",
    "    def call(self, x):\n",
    "        Mx=tf.multiply(self.mask,x)\n",
    "        Rxx=tf.matmul(Mx,Mx,transpose_b=True)\n",
    "        Rxx = 1-normalize_with_moments(Rxx)\n",
    "        xRxx=tf.matmul(Rxx,Mx)\n",
    "\n",
    "        query_value_attention_seq = layers.Attention()([xRxx, Mx])\n",
    "        query_value_attention_seq=tf.expand_dims(query_value_attention_seq,2)\n",
    "        # query_value_attention_seq=normalize_with_moments(query_value_attention_seq)\n",
    "        query_value_attention = layers.GlobalAveragePooling1D()(\n",
    "            query_value_attention_seq)\n",
    "        Mx=tf.expand_dims(Mx,2)\n",
    "        query_value_attention_seq=tf.multiply(query_value_attention_seq,self.w)\n",
    "        concatenated = layers.Concatenate()(\n",
    "            [Mx, query_value_attention_seq])\n",
    "        \n",
    "        print(concatenated.shape)\n",
    "        return concatenated\n",
    "\n",
    "def getModel(inputSize):\n",
    "    \n",
    "    inputs = layers.Input(shape=inputSize)\n",
    "    concatenated=calculateInteraction(inputs.shape[1])(inputs)\n",
    "    concatenated=layers.Flatten()(concatenated)\n",
    "    x=layers.Dense(64)(concatenated)\n",
    "    x=layers.Dense(16)(x)\n",
    "    output=layers.Dense(3,activation='softmax')(x)\n",
    "    \n",
    "    METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "     ]   \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=METRICS)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 9.5913 - accuracy: 0.9171 - precision: 0.8756 - recall: 0.8756 - auc: 0.9441 - val_loss: 3.1255 - val_accuracy: 0.7600 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.7732\n",
      "Epoch 641/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5934 - accuracy: 0.9182 - precision: 0.8858 - recall: 0.8656 - auc: 0.9469 - val_loss: 2.7459 - val_accuracy: 0.7600 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.7764\n",
      "Epoch 642/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.5725 - accuracy: 0.8772 - precision: 0.8230 - recall: 0.8042 - auc: 0.9430 - val_loss: 3.6694 - val_accuracy: 0.7600 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.8104\n",
      "Epoch 643/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3261 - accuracy: 0.9598 - precision: 0.9397 - recall: 0.9397 - auc: 0.9899 - val_loss: 3.2300 - val_accuracy: 0.7600 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.7844\n",
      "Epoch 644/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5731 - accuracy: 0.9637 - precision: 0.9455 - recall: 0.9455 - auc: 0.9956 - val_loss: 3.8137 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7752\n",
      "Epoch 645/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5493 - accuracy: 0.9818 - precision: 0.9781 - recall: 0.9668 - auc: 0.9936 - val_loss: 3.1899 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7792\n",
      "Epoch 646/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2057 - accuracy: 0.9960 - precision: 0.9940 - recall: 0.9940 - auc: 0.9994 - val_loss: 3.8039 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7776\n",
      "Epoch 647/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0763 - accuracy: 0.9715 - precision: 0.9640 - recall: 0.9500 - auc: 0.9972 - val_loss: 2.6198 - val_accuracy: 0.7600 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.7656\n",
      "Epoch 648/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3379 - accuracy: 0.9922 - precision: 0.9882 - recall: 0.9882 - auc: 0.9993 - val_loss: 3.2721 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7460\n",
      "Epoch 649/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5470 - accuracy: 0.9454 - precision: 0.9182 - recall: 0.9182 - auc: 0.9920 - val_loss: 2.5226 - val_accuracy: 0.7333 - val_precision: 0.6000 - val_recall: 0.6000 - val_auc: 0.8032\n",
      "Epoch 650/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.1881 - accuracy: 0.9276 - precision: 0.8970 - recall: 0.8842 - auc: 0.9880 - val_loss: 4.3197 - val_accuracy: 0.6800 - val_precision: 0.5200 - val_recall: 0.5200 - val_auc: 0.7276\n",
      "Epoch 651/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.1360 - accuracy: 0.9023 - precision: 0.8612 - recall: 0.8418 - auc: 0.9629 - val_loss: 3.0939 - val_accuracy: 0.7333 - val_precision: 0.6000 - val_recall: 0.6000 - val_auc: 0.7764\n",
      "Epoch 652/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7701 - accuracy: 0.9701 - precision: 0.9582 - recall: 0.9516 - auc: 0.9948 - val_loss: 3.4409 - val_accuracy: 0.7600 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.7500\n",
      "Epoch 653/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.0954 - accuracy: 0.9208 - precision: 0.8813 - recall: 0.8813 - auc: 0.9787 - val_loss: 2.6751 - val_accuracy: 0.7333 - val_precision: 0.6000 - val_recall: 0.6000 - val_auc: 0.7792\n",
      "Epoch 654/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7272 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3924 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 655/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8261 - accuracy: 0.9867 - precision: 0.9801 - recall: 0.9801 - auc: 0.9992 - val_loss: 3.5089 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7544\n",
      "Epoch 656/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3697 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5419 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7724\n",
      "Epoch 657/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7955 - accuracy: 0.9968 - precision: 0.9952 - recall: 0.9952 - auc: 1.0000 - val_loss: 3.5480 - val_accuracy: 0.7600 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.7648\n",
      "Epoch 658/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6909 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5674 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7744\n",
      "Epoch 659/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5396 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3754 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7720\n",
      "Epoch 660/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4512 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6415 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7544\n",
      "Epoch 661/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5031 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4825 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 662/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4576 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.0158 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7696\n",
      "Epoch 663/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4039 - accuracy: 0.9980 - precision: 0.9970 - recall: 0.9970 - auc: 1.0000 - val_loss: 3.6288 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7500\n",
      "Epoch 664/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6954 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2824 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7712\n",
      "Epoch 665/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5203 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.0105 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7924\n",
      "Epoch 666/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5887 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3251 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7712\n",
      "Epoch 667/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4279 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4066 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 668/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5355 - accuracy: 0.9968 - precision: 0.9952 - recall: 0.9952 - auc: 0.9999 - val_loss: 3.4687 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7704\n",
      "Epoch 669/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4288 - accuracy: 0.9904 - precision: 0.9856 - recall: 0.9856 - auc: 0.9999 - val_loss: 3.3543 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7712\n",
      "Epoch 670/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5067 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.0690 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7736\n",
      "Epoch 671/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.9771 - precision: 0.9656 - recall: 0.9656 - auc: 0.9989 - val_loss: 3.4717 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7768\n",
      "Epoch 672/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4071 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4109 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 673/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4439 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1983 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7736\n",
      "Epoch 674/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3872 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2916 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7712\n",
      "Epoch 675/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4192 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3737 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7712\n",
      "Epoch 676/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3434 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4659 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 677/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5335 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4857 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 678/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4333 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4639 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 679/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5295 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2034 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7688\n",
      "Epoch 680/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5311 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4610 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7720\n",
      "Epoch 681/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3783 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5706 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 682/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3350 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3811 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7712\n",
      "Epoch 683/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3542 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2831 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7712\n",
      "Epoch 684/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4573 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5551 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 685/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3188 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3802 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7712\n",
      "Epoch 686/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3202 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4059 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7712\n",
      "Epoch 687/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3741 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5103 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7716\n",
      "Epoch 688/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4577 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5807 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7712\n",
      "Epoch 689/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4126 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4292 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7712\n",
      "Epoch 690/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3785 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6818 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 691/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3061 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6107 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7716\n",
      "Epoch 692/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3840 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7841 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7720\n",
      "Epoch 693/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3026 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6575 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7708\n",
      "Epoch 694/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2710 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7055 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7692\n",
      "Epoch 695/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3994 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8274 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7720\n",
      "Epoch 696/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3703 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7268 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7720\n",
      "Epoch 697/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2712 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8542 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 698/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2638 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7564 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7720\n",
      "Epoch 699/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3034 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7292 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7720\n",
      "Epoch 700/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3256 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6910 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7708\n",
      "Epoch 701/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3267 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8719 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7720\n",
      "Epoch 702/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3363 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9206 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7764\n",
      "Epoch 703/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3465 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5954 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7712\n",
      "Epoch 704/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2618 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9104 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7744\n",
      "Epoch 705/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8038 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 706/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6554 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7712\n",
      "Epoch 707/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3829 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6708 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7720\n",
      "Epoch 708/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3549 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7417 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7752\n",
      "Epoch 709/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2789 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8986 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7744\n",
      "Epoch 710/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2501 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8921 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7776\n",
      "Epoch 711/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2023 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8411 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7744\n",
      "Epoch 712/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3743 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6207 - val_accuracy: 0.7867 - val_precision: 0.6800 - val_recall: 0.6800 - val_auc: 0.7776\n",
      "Epoch 713/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3954 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0824 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7760\n",
      "Epoch 714/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3305 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0408 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7744\n",
      "Epoch 715/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3300 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6167 - val_accuracy: 0.8000 - val_precision: 0.7083 - val_recall: 0.6800 - val_auc: 0.7716\n",
      "Epoch 716/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4705 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0532 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7784\n",
      "Epoch 717/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3474 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8593 - val_accuracy: 0.8133 - val_precision: 0.7200 - val_recall: 0.7200 - val_auc: 0.7720\n",
      "Epoch 00717: early stopping\n"
     ]
    }
   ],
   "source": [
    "total=lesions_encoded.shape[0]\n",
    "c1=len(np.where(lesions_encoded[:,0]==1)[0])\n",
    "c2=len(np.where(lesions_encoded[:,1]==1)[0])\n",
    "c3=len(np.where(lesions_encoded[:,2]==1)[0])\n",
    "\n",
    "model=getModel(X_train.shape[1])\n",
    "\n",
    "batch_size=16\n",
    "weight_for_0 = (batch_size / c1)*(total)/3.0 \n",
    "weight_for_1 = (batch_size / c2)*(total)/3.0\n",
    "weight_for_2 = (batch_size/ c3)*(total)/3.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1,2:weight_for_2}\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_recall', mode='max', verbose=1,baseline=0.75,patience=699)\n",
    "history=model.fit(X_train,y_train,epochs=1000,batch_size=batch_size,validation_split=0.2,class_weight=class_weight,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(None, 697, 14)\n              precision    recall  f1-score   support\n\n           1       0.90      1.00      0.95         9\n           2       0.33      0.33      0.33         6\n           3       0.73      0.69      0.71        16\n\n    accuracy                           0.71        31\n   macro avg       0.66      0.67      0.66        31\nweighted avg       0.70      0.71      0.71        31\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labelNames=['hyperplasic', 'serrated', 'adenoma']\n",
    "y_output=model.predict(X_test)\n",
    "y_output_transformed= onehot_encoder.inverse_transform(y_output)\n",
    "y_test_transformed= onehot_encoder.inverse_transform(y_test)\n",
    "print(classification_report(y_test_transformed, y_output_transformed, labels=[1,2,3]))\n",
    "\n",
    "y_output_train=model.predict(X_train)\n",
    "y_output_transformed_train= onehot_encoder.inverse_transform(y_output_train)\n",
    "y_train_transformed= onehot_encoder.inverse_transform(y_train)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}